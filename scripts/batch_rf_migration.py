#!/usr/bin/env python3
"""
RFå…¨é‡æ‰¹é‡è¿ç§»è„šæœ¬
è‡ªåŠ¨åŒ–è¿ç§»å…¨éƒ¨59ä¸ªFCåˆ°RFç‰ˆæœ¬
"""

import sys
import os
import yaml
from pathlib import Path
from typing import Dict, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))


class BatchRFMigrator:
    """RFå…¨é‡æ‰¹é‡è¿ç§»å™¨"""

    def __init__(self):
        self.fc_dir = Path(__file__).parent.parent / "workflows/fc"
        self.migration_results = []
        self.start_time = time.time()

    def migrate_all_fcs(self) -> Dict:
        """æ‰¹é‡è¿ç§»å…¨éƒ¨FCåˆ°RFç‰ˆæœ¬"""
        print("ğŸš€ å¼€å§‹RFå…¨é‡æ‰¹é‡è¿ç§»\n")

        # è·å–æ‰€æœ‰FCæ–‡ä»¶
        all_yaml_files = sorted(self.fc_dir.glob("naohai_FC_NH_*.yaml"))
        original_fc_files = [f for f in all_yaml_files if not f.stem.endswith('_rf')]
        rf_files = sorted(self.fc_dir.glob("naohai_FC_NH_*_rf.yaml"))

        existing_rf_basenames = {p.stem.replace('_rf', '') for p in rf_files}
        fc_to_migrate = [f for f in original_fc_files if f.stem not in existing_rf_basenames]

        print(f"ğŸ“Š å‘ç° {len(all_yaml_files)} ä¸ªå·¥ä½œæµæ–‡ä»¶ï¼ˆåŸç‰ˆ {len(original_fc_files)} / RF {len(rf_files)}ï¼‰")
        print(f"ğŸ¯ éœ€è¦è¿ç§» {len(fc_to_migrate)} ä¸ªFC\n")

        # æŒ‰ä¸šåŠ¡é¢†åŸŸåˆ†ç»„
        fc_groups = self._group_fcs_by_business_area(fc_to_migrate)

        # å¹¶è¡Œè¿ç§»æ¯ç»„
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_group = {}

            for group_name, fc_paths in fc_groups.items():
                print(f"ğŸ”„ å¼€å§‹è¿ç§»ç»„: {group_name} ({len(fc_paths)} ä¸ª)")

                # ä¸ºæ¯ä¸ªFCç»„åˆ›å»ºè¿ç§»future
                group_futures = []
                for fc_path in fc_paths:
                    future = executor.submit(self._migrate_single_fc, fc_path)
                    group_futures.append(future)

                future_to_group[group_name] = group_futures

            # ç­‰å¾…æ‰€æœ‰ç»„å®Œæˆ
            all_futures = []
            for group_futures in future_to_group.values():
                all_futures.extend(group_futures)

            # æ”¶é›†ç»“æœ
            for future in as_completed(all_futures):
                try:
                    result = future.result()
                    self.migration_results.append(result)
                except Exception as e:
                    print(f"âŒ FCè¿ç§»å¤±è´¥: {e}")

        # ç”Ÿæˆå…¨é‡æŠ¥å‘Šï¼ˆåŸºäºå½“å‰ç›®å½•ä¸‹å…¨éƒ¨RFç‰ˆæœ¬ï¼Œè€Œä¸æ˜¯â€œæœ¬æ¬¡è¿ç§»äº†å¤šå°‘ä¸ªâ€ï¼‰
        migrated_in_this_run = {p.stem for p in fc_to_migrate}
        full_results = self._build_full_results(migrated_in_this_run)
        migration_report = self._generate_migration_report(full_results, migrated_in_this_run, len(all_yaml_files), len(original_fc_files), len(rf_files))

        end_time = time.time()
        migration_report['execution_time'] = {
            'start_time': self.start_time,
            'end_time': end_time,
            'duration_minutes': (end_time - self.start_time) / 60
        }

        return migration_report

    def _build_full_results(self, migrated_in_this_run: set[str]) -> List[Dict]:
        """åŸºäºå½“å‰ç›®å½•ä¸‹å…¨éƒ¨RFç‰ˆæœ¬ï¼Œæ„å»ºå…¨é‡éªŒè¯ç»“æœ"""
        rf_files = sorted(self.fc_dir.glob("naohai_FC_NH_*_rf.yaml"))
        results: List[Dict] = []

        for rf_path in rf_files:
            original_path = rf_path.with_name(rf_path.name.replace('_rf.yaml', '.yaml'))
            fc_name = original_path.name

            if not original_path.exists():
                results.append({
                    'original_fc': str(original_path),
                    'rf_fc': str(rf_path),
                    'fc_name': fc_name,
                    'success': False,
                    'error': 'å¯¹åº”çš„åŸç‰ˆFCä¸å­˜åœ¨ï¼Œæ— æ³•ç”Ÿæˆå¯¹æ¯”æŒ‡æ ‡',
                    'migrated_in_this_run': False,
                    'selector_reduction': 0,
                    'semantic_actions_added': 0,
                })
                continue

            validation = self._validate_migration(original_path, rf_path)
            validation_error = validation.get('validation_error')
            results.append({
                'original_fc': str(original_path),
                'rf_fc': str(rf_path),
                'fc_name': fc_name,
                'success': validation_error is None,
                'validation': validation,
                'migrated_in_this_run': original_path.stem in migrated_in_this_run,
                'selector_reduction': validation.get('selector_reduction', 0),
                'semantic_actions_added': validation.get('semantic_actions_added', 0),
                **({'error': validation_error} if validation_error else {})
            })

        return results

    def _group_fcs_by_business_area(self, fc_files: List[Path]) -> Dict[str, List[Path]]:
        """æŒ‰ä¸šåŠ¡é¢†åŸŸåˆ†ç»„FC"""
        groups = {
            'core_navigation': [],      # è¿›å…¥AIåˆ›ä½œã€å‰§æœ¬åˆ—è¡¨
            'story_management': [],      # å‰§æœ¬æ“ä½œã€èœå•
            'character_scene': [],         # è§’è‰²ã€åœºæ™¯ç®¡ç†
            'storyboard_video': [],       # åˆ†é•œã€è§†é¢‘åˆ›ä½œ
            'export_upload': []           # å¯¼å‡ºã€ä¸Šä¼ åŠŸèƒ½
        }

        for fc_file in fc_files:
            with open(fc_file, 'r', encoding='utf-8') as f:
                workflow = yaml.safe_load(f)
                description = workflow.get('workflow', {}).get('description', '').lower()

            # æ ¹æ®æè¿°åˆ†ç»„
            if 'aiåˆ›ä½œ' in description or 'å‰§æœ¬åˆ—è¡¨' in description:
                groups['core_navigation'].append(fc_file)
            elif 'è§’è‰²' in description or 'ç»‘å®š' in description:
                groups['character_scene'].append(fc_file)
            elif 'åˆ†é•œ' in description or 'æ•…äº‹æ¿' in description:
                groups['storyboard_video'].append(fc_file)
            elif 'å¯¼å‡º' in description or 'ä¸Šä¼ ' in description:
                groups['export_upload'].append(fc_file)
            else:
                groups['story_management'].append(fc_file)

        return groups

    def _migrate_single_fc(self, fc_path: Path) -> Dict:
        """è¿ç§»å•ä¸ªFCåˆ°RFç‰ˆæœ¬"""
        try:
            fc_name = fc_path.name
            print(f"  ğŸ”„ è¿ç§» {fc_name}")

            # è§£æåŸç‰ˆFC
            with open(fc_path, 'r', encoding='utf-8') as f:
                original_workflow = yaml.safe_load(f)

            # ç”ŸæˆRFç‰ˆæœ¬
            rf_workflow = self._convert_to_rf_version(original_workflow)

            # ä¿å­˜RFç‰ˆæœ¬
            rf_path = fc_path.parent / f"{fc_path.stem}_rf.yaml"
            with open(rf_path, 'w', encoding='utf-8') as f:
                yaml.dump(rf_workflow, f, allow_unicode=True, default_flow_style=False)

            # éªŒè¯è¿ç§»ç»“æœ
            validation = self._validate_migration(fc_path, rf_path)

            result = {
                'original_fc': str(fc_path),
                'rf_fc': str(rf_path),
                'fc_name': fc_name,
                'success': True,
                'validation': validation,
                'selector_reduction': validation.get('selector_reduction', 0),
                'semantic_actions_added': validation.get('semantic_actions_added', 0)
            }

            print(f"    âœ… {fc_name} è¿ç§»å®Œæˆ")
            return result

        except Exception as e:
            print(f"    âŒ {fc_name} è¿ç§»å¤±è´¥: {e}")
            return {
                'original_fc': str(fc_path),
                'rf_fc': str(fc_path),
                'fc_name': fc_path.name if 'fc_path' in locals() else 'unknown',
                'success': False,
                'error': str(e),
                'selector_reduction': 0,
                'semantic_actions_added': 0
            }

    def _convert_to_rf_version(self, original_workflow: Dict) -> Dict:
        """å°†åŸç‰ˆworkflowè½¬æ¢ä¸ºRFç‰ˆæœ¬"""
        rf_workflow = {
            'workflow': {
                'name': original_workflow['workflow']['name'] + '_rf',
                'description': original_workflow['workflow']['description'] + ' (RFç‰ˆæœ¬)',
                'version': 'rf-v1.0'
            }
        }

        # åˆ†æåŸç‰ˆworkflowï¼Œæå–å…¬å…±è·¯å¾„
        common_actions = self._extract_common_actions(original_workflow)

        if common_actions:
            rf_workflow['workflow']['suite_setup'] = common_actions
            print(f"    ğŸ“¦ æå– {len(common_actions)} ä¸ªå…¬å…±æ­¥éª¤åˆ° suite_setup")

        # è½¬æ¢phases
        rf_phases = []
        for phase in original_workflow['workflow'].get('phases', []):
            rf_phase = self._convert_phase_to_rf(phase)
            if rf_phase:
                rf_phases.append(rf_phase)

        if rf_phases:
            rf_workflow['workflow']['phases'] = rf_phases

        # æ·»åŠ RFç‰¹æ€§
        rf_workflow['workflow']['success_criteria'] = self._generate_success_criteria(original_workflow)
        rf_workflow['workflow']['error_recovery'] = self._generate_error_recovery(original_workflow)

        return rf_workflow

    def _extract_common_actions(self, workflow: Dict) -> List[Dict]:
        """æå–å…¬å…±actionåˆ°suite_setup"""
        common_patterns = {
            'open_page': {'url': '${test.url}'},
            'wait_for': {'condition': {'selector': 'body', 'visible': True}},
            'assert_logged_in': {}
        }

        # ç»Ÿè®¡é«˜é¢‘actions
        action_counts = {}
        for phase in workflow.get('workflow', {}).get('phases', []):
            for step in phase.get('steps', []):
                action = step.get('action', '')
                if action in action_counts:
                    action_counts[action] += 1
                else:
                    action_counts[action] = 1

        # æå–å‡ºç°2æ¬¡ä»¥ä¸Šçš„actionsä½œä¸ºå…¬å…±æ­¥éª¤ - ä¿®å¤breaké€»è¾‘
        common_actions = []
        for action_pattern, params_template in common_patterns.items():
            if action_counts.get(action_pattern, 0) >= 2:
                # é€‚é…å‚æ•°
                actual_params = {}
                found_first = False
                for phase in workflow.get('workflow', {}).get('phases', []):
                    for step in phase.get('steps', []):
                        if step.get('action', '') == action_pattern:
                            actual_params = {k: v for k, v in step.items() if k != 'action'}
                            found_first = True
                            break
                    if found_first:
                        break

                # åˆå¹¶æ¨¡æ¿å’Œå®é™…å‚æ•°
                merged_params = {**params_template, **actual_params}
                common_actions.append({
                    'action': action_pattern,
                    **merged_params
                })

        return common_actions

    def _convert_phase_to_rf(self, phase: Dict) -> Dict:
        """è½¬æ¢å•ä¸ªphaseåˆ°RFç‰ˆæœ¬"""
        rf_steps = []
        selector_count = 0
        semantic_action_count = 0

        for step in phase.get('steps', []):
            if 'selector' in step:
                selector_count += 1

            # å°è¯•è¯­ä¹‰åŒ–
            semantic_action = self._try_semantic_conversion(step)
            if semantic_action:
                rf_steps.append(semantic_action)
                semantic_action_count += 1
            else:
                rf_steps.append(step)

        return {
            'name': phase.get('name'),
            'description': phase.get('description') + ' (RFè¯­ä¹‰åŒ–ï¼‰',
            'steps': rf_steps,
            'metadata': {
                'selector_count': selector_count,
                'semantic_action_count': semantic_action_count,
                'conversion_rate': semantic_action_count / len(rf_steps) if rf_steps else 0
            }
        }

    def _try_semantic_conversion(self, step: Dict) -> Dict:
        """å°è¯•å°†stepè½¬æ¢ä¸ºè¯­ä¹‰action"""
        selector = step.get('selector', '')
        action_type = step.get('action', '')

        # è¯­ä¹‰åŒ–è§„åˆ™æ˜ å°„
        semantic_rules = {
            '.nav-routerTo-item:has-text("AIåˆ›ä½œ")': {
                'action': 'rf_enter_ai_creation',
                'remove_selector': True
            },
            'div.list-item:not(.add-item)': {
                'action': 'rf_ensure_story_exists',
                'remove_selector': True
            },
            'text=åˆ†é•œç®¡ç†': {
                'action': 'rf_enter_storyboard_management',
                'remove_selector': True
            },
            'text=è§†é¢‘åˆ›ä½œ': {
                'action': 'rf_select_fusion_generation',
                'remove_selector': True
            },
            'text=æ¨¡å‹ç”Ÿæˆ': {
                'action': 'rf_create_scene_mode',
                'params': {'mode': 'generate'},
                'remove_selector': True
            },
            'text=è‡ªå·±ä¸Šä¼ ': {
                'action': 'rf_create_scene_mode',
                'params': {'mode': 'upload'},
                'remove_selector': True
            },
            'text=å»ºè®®åˆ†é•œ': {
                'action': 'rf_suggest_shot_count',
                'remove_selector': True
            },
            '.suggest-count': {
                'action': 'rf_suggest_shot_count',
                'remove_selector': True
            },
            '.video-fragment:first-child': {
                'action': 'rf_select_video_segments',
                'remove_selector': True
            },
            'text=ä¿å­˜é€‰æ‹©': {
                'action': 'rf_select_video_segments',
                'remove_selector': True
            },
            'div.episode-item:has-text(': {
                'action': 'rf_open_episode_menu',
                'remove_selector': True
            },
        }

        # æ£€æŸ¥selectoråŒ¹é…
        for pattern, semantic_info in semantic_rules.items():
            if pattern in selector:
                rf_step = {
                    'action': semantic_info['action'],
                    'timeout': step.get('timeout', '${test.timeout.element_load}'),
                    **(semantic_info.get('params', {}) or {}),
                }

                # ä¿ç•™éselectorå‚æ•°
                for key, value in step.items():
                    if key != 'action' and key != 'selector':
                        rf_step[key] = value

                return rf_step

        return None  # æ— æ³•è¯­ä¹‰åŒ–ï¼Œä¿æŒåŸæ ·

    def _generate_success_criteria(self, workflow: Dict) -> List[str]:
        """ç”ŸæˆæˆåŠŸæ ‡å‡†"""
        return [
            "æˆåŠŸè¿›å…¥AIåˆ›ä½œæ¨¡å—",
            "ä¸šåŠ¡é€»è¾‘éªŒè¯é€šè¿‡",
            "RFè¯­ä¹‰åŒ–æ”¹è¿›ç”Ÿæ•ˆ",
            "å‘åå…¼å®¹æ€§ä¿æŒ"
        ]

    def _generate_error_recovery(self, workflow: Dict) -> List[Dict]:
        """ç”Ÿæˆé”™è¯¯æ¢å¤ç­–ç•¥"""
        return [
            {
                'action': 'rf_enter_ai_creation',
                'timeout': '${test.timeout.element_load}'
            },
            {
                'action': 'rf_ensure_story_exists',
                'timeout': '${test.timeout.element_load}'
            }
        ]

    def _validate_migration(self, original_path: Path, rf_path: Path) -> Dict:
        """éªŒè¯è¿ç§»ç»“æœ"""
        try:
            # å°è¯•åˆ›å»ºRFç‰ˆæœ¬çš„actions
            with open(rf_path, 'r', encoding='utf-8') as f:
                rf_workflow = yaml.safe_load(f)

            # ç»Ÿè®¡selectorå‡å°‘
            original_selectors = self._count_selectors(original_path)
            rf_selectors = self._count_selectors(rf_path)

            # ç»Ÿè®¡semantic actions
            semantic_actions = self._count_semantic_actions(rf_path)

            return {
                'selector_reduction': original_selectors - rf_selectors,
                'semantic_actions_added': semantic_actions,
                'selector_reduction_rate': (original_selectors - rf_selectors) / original_selectors if original_selectors > 0 else 0
            }

        except Exception as e:
            return {
                'validation_error': str(e),
                'selector_reduction': 0,
                'semantic_actions_added': 0
            }

    def _count_selectors(self, yaml_path: Path) -> int:
        """ç»Ÿè®¡æ–‡ä»¶ä¸­çš„selectoræ•°é‡"""
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                content = f.read()
                return content.count('selector:')
        except:
            return 0

    def _count_semantic_actions(self, yaml_path: Path) -> int:
        """ç»Ÿè®¡æ–‡ä»¶ä¸­çš„semantic actionæ•°é‡"""
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                workflow = yaml.safe_load(f) or {}

            count = 0
            wf = workflow.get('workflow', {})

            for step in wf.get('suite_setup', []) or []:
                if isinstance(step, dict) and str(step.get('action', '')).startswith('rf_'):
                    count += 1

            for phase in wf.get('phases', []) or []:
                for step in phase.get('steps', []) or []:
                    if isinstance(step, dict) and str(step.get('action', '')).startswith('rf_'):
                        count += 1

            for step in wf.get('error_recovery', []) or []:
                if isinstance(step, dict) and str(step.get('action', '')).startswith('rf_'):
                    count += 1

            return count
        except Exception:
            return 0

    def _generate_migration_report(
        self,
        full_results: List[Dict],
        migrated_in_this_run: set[str],
        all_workflow_files: int,
        original_fc_files: int,
        rf_files: int,
    ) -> Dict:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Šï¼ˆå…¨é‡ï¼šä»¥å½“å‰RFæ–‡ä»¶ä¸ºå‡†ï¼‰"""
        successful_migrations = [r for r in full_results if r.get('success')]
        failed_migrations = [r for r in full_results if not r.get('success')]

        # ç»Ÿè®¡æŒ‡æ ‡
        total_selector_reduction = sum(r.get('selector_reduction', 0) for r in successful_migrations)
        total_semantic_actions = sum(r.get('semantic_actions_added', 0) for r in successful_migrations)

        return {
            'run_context': {
                'discovered_workflow_files': all_workflow_files,
                'discovered_original_fcs': original_fc_files,
                'discovered_rf_versions': rf_files,
                'migrated_in_this_run': len(migrated_in_this_run),
            },
            'migration_summary': {
                'total_fcs': len(full_results),
                'successful': len(successful_migrations),
                'failed': len(failed_migrations),
                'success_rate': len(successful_migrations) / len(full_results) * 100 if full_results else 0
            },
            'improvement_metrics': {
                'total_selector_reduction': total_selector_reduction,
                'total_semantic_actions': total_semantic_actions,
                'avg_selector_reduction_per_fc': total_selector_reduction / len(successful_migrations) if successful_migrations else 0,
                'avg_semantic_actions_per_fc': total_semantic_actions / len(successful_migrations) if successful_migrations else 0
            },
            'detailed_results': full_results,
            'failed_migrations': failed_migrations
        }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ RFå…¨é‡æ‰¹é‡è¿ç§»å¼€å§‹\n")

    migrator = BatchRFMigrator()

    # æ‰§è¡Œå…¨é‡è¿ç§»
    migration_report = migrator.migrate_all_fcs()

    # ä¿å­˜è¿ç§»æŠ¥å‘Š
    report_path = Path(__file__).parent.parent / "docs/rf_full_migration_report.yaml"
    with open(report_path, 'w', encoding='utf-8') as f:
        yaml.dump(migration_report, f, allow_unicode=True, default_flow_style=False)

    # è¾“å‡ºæ‘˜è¦
    summary = migration_report['migration_summary']
    metrics = migration_report['improvement_metrics']

    print(f"\nğŸ‰ RFå…¨é‡è¿ç§»å®Œæˆï¼")
    print(f"ğŸ“Š è¿ç§»æ‘˜è¦:")
    print(f"  æ€»FCæ•°: {summary['total_fcs']}")
    print(f"  æˆåŠŸ: {summary['successful']}")
    print(f"  å¤±è´¥: {summary['failed']}")
    print(f"  æˆåŠŸç‡: {summary['success_rate']:.1f}%")

    print(f"\nğŸ“ˆ æ”¹è¿›æŒ‡æ ‡:")
    print(f"  Selectoræ€»å‡å°‘: {metrics['total_selector_reduction']}")
    print(f"  å¹³å‡æ¯FCå‡å°‘: {metrics['avg_selector_reduction_per_fc']:.1f}")
    print(f"  è¯­ä¹‰Actionæ€»æ•°: {metrics['total_semantic_actions']}")
    print(f"  å¹³å‡æ¯FCå¢åŠ : {metrics['avg_semantic_actions_per_fc']:.1f}")

    if summary['success_rate'] >= 90:
        print("ğŸ¯ è¿ç§»è´¨é‡ï¼šä¼˜ç§€")
        return 0
    elif summary['success_rate'] >= 75:
        print("ğŸ¯ è¿ç§»è´¨é‡ï¼šè‰¯å¥½")
        return 0
    else:
        print("âš ï¸  è¿ç§»éœ€è¦ä¼˜åŒ–")
        return 1


if __name__ == "__main__":
    sys.exit(main())
